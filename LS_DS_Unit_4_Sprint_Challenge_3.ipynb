{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_4 (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeffrowetull/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/LS_DS_Unit_4_Sprint_Challenge_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGbpg3ga3Ho-",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe the difference between a discriminator and generator in a GAN\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - RNNs\n",
        "\n",
        "Use an RNN to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PQdj-7P3rUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy==1.16.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT5E4ZFJLc6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZitSk8HS6G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "num_classes = 46\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "e74cd0ff-c683-43d6-c90c-c4d6d177c2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "e6de6198-adb8-43cb-ec23-c1d9da64c53f"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8982 train sequences\n",
            "2246 test sequences\n",
            "x_train shape: (8982, 80)\n",
            "x_test shape: (2246, 80)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 46)                5934      \n",
            "=================================================================\n",
            "Total params: 2,697,518\n",
            "Trainable params: 2,697,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdpqXk4OCCEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "985ed9dd-0811-4b73-ec99-d9292e95f11e"
      },
      "source": [
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/10\n",
            "8982/8982 [==============================] - 87s 10ms/step - loss: 2.2348 - acc: 0.4251 - val_loss: 1.7803 - val_acc: 0.5142\n",
            "Epoch 2/10\n",
            "8982/8982 [==============================] - 55s 6ms/step - loss: 1.7253 - acc: 0.5413 - val_loss: 1.6397 - val_acc: 0.5623\n",
            "Epoch 3/10\n",
            "8982/8982 [==============================] - 56s 6ms/step - loss: 1.5075 - acc: 0.5923 - val_loss: 1.5362 - val_acc: 0.5962\n",
            "Epoch 4/10\n",
            "8982/8982 [==============================] - 55s 6ms/step - loss: 1.2910 - acc: 0.6500 - val_loss: 1.4761 - val_acc: 0.6207\n",
            "Epoch 5/10\n",
            "8982/8982 [==============================] - 56s 6ms/step - loss: 1.0931 - acc: 0.7095 - val_loss: 1.3978 - val_acc: 0.6701\n",
            "Epoch 6/10\n",
            "8982/8982 [==============================] - 55s 6ms/step - loss: 0.9021 - acc: 0.7585 - val_loss: 1.4158 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "8982/8982 [==============================] - 55s 6ms/step - loss: 0.7493 - acc: 0.8032 - val_loss: 1.4260 - val_acc: 0.6647\n",
            "Epoch 8/10\n",
            "8982/8982 [==============================] - 55s 6ms/step - loss: 0.6352 - acc: 0.8338 - val_loss: 1.4257 - val_acc: 0.6732\n",
            "Epoch 9/10\n",
            "8982/8982 [==============================] - 55s 6ms/step - loss: 0.5452 - acc: 0.8575 - val_loss: 1.4635 - val_acc: 0.6781\n",
            "Epoch 10/10\n",
            "8982/8982 [==============================] - 55s 6ms/step - loss: 0.4513 - acc: 0.8849 - val_loss: 1.4982 - val_acc: 0.6772\n",
            "2246/2246 [==============================] - 3s 1ms/step\n",
            "Test score: 1.4982073921660495\n",
            "Test accuracy: 0.6772039181296569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lPn6c0x21gu1"
      },
      "source": [
        "Conclusion - RNN runs, and gives pretty decent improvement over a naive model. To *really* improve the model, more playing with parameters would help. Also - RNN may well not be the best approach here, but it is at least a valid one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "69f86f64-7fb0-4ad7-8725-d47d495b016d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_images_download\n",
            "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
            "Collecting selenium (from google_images_download)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n",
            "Building wheels for collected packages: google-images-download\n",
            "  Building wheel for google-images-download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/28/ad/f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
            "Successfully built google-images-download\n",
            "Installing collected packages: selenium, google-images-download\n",
            "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "29aa3cec-28d8-4ed5-fb70-f6c100baf8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"animal pond\", \"limit\": 5, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = animal pond\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: https://www.enchantedlearning.com/pgifs/Pondanimals.GIF\n",
            "Completed Image ====> 1.Pondanimals.GIF\n",
            "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
            "Completed Image ====> 2.hqdefault.jpg\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
            "Completed Image ====> 3.PKLS4116_inline.png\n",
            "Image URL: https://get.pxhere.com/photo/water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "Completed Image ====> 4.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
            "Completed Image ====> 5.PKLS4116.png\n",
            "\n",
            "Errors: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goal* - also check for fish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "232e32e0-45a2-4efd-b7b8-b92ed2747e96"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "def process_image(path):\n",
        "  return image.load_img(path, target_size=(224,224))\n",
        "\n",
        "def is_frog_or_fish(img):\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  model = ResNet50(weights='imagenet')\n",
        "  features = model.predict(x)\n",
        "  results = decode_predictions(features, top=3)[0]\n",
        "  print(results)\n",
        "  for entry in results:\n",
        "    if 'bullfrog'  in entry[1]:\n",
        "      return entry[2], f'I have detected a {entry[1]}'\n",
        "    elif 'fish' in entry[1]:\n",
        "      return entry[2], 'I have detected a fish'\n",
        "    else:\n",
        "      return 'incorrect animals'\n",
        "    \n",
        "for i in absolute_image_paths[0]['animal pond']:\n",
        "  print(i.split('/')[-1:])\n",
        "  print(is_frog_or_fish(process_image(i)))\n",
        "  print('-'*50)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1.Pondanimals.GIF']\n",
            "[('n03598930', 'jigsaw_puzzle', 0.8680313), ('n06359193', 'web_site', 0.06410024), ('n02834397', 'bib', 0.021264324)]\n",
            "incorrect animals\n",
            "--------------------------------------------------\n",
            "['2.hqdefault.jpg']\n",
            "[('n01443537', 'goldfish', 0.8495859), ('n01631663', 'eft', 0.06760218), ('n02536864', 'coho', 0.035163548)]\n",
            "(0.8495859, 'I have detected a fish')\n",
            "--------------------------------------------------\n",
            "['3.PKLS4116_inline.png']\n",
            "[('n04243546', 'slot', 0.8712449), ('n04476259', 'tray', 0.04993588), ('n03908618', 'pencil_box', 0.023072386)]\n",
            "incorrect animals\n",
            "--------------------------------------------------\n",
            "['4.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg']\n",
            "[('n02442845', 'mink', 0.3097652), ('n02363005', 'beaver', 0.23399033), ('n02361337', 'marmot', 0.20796789)]\n",
            "incorrect animals\n",
            "--------------------------------------------------\n",
            "['5.PKLS4116.png']\n",
            "[('n03485794', 'handkerchief', 0.8822726), ('n02834397', 'bib', 0.022680892), ('n03291819', 'envelope', 0.020095171)]\n",
            "incorrect animals\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Generative Adverserial Networks (GANS)\n",
        "\n",
        "Describe the difference between a discriminator and generator in a GAN in your own words.\n",
        "\n",
        "__*Your Answer:*__  The generator will deconvolute a set of numbers to create an object. The discriminator will evaluate that object based on its training. The generator will go on to make a new object. Back propagation is applied to both networks so that the generator will create better objects and the discriminator will become better at flagging synthetic objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "\n",
        "I think sql is my strongest area followed by regression and classification\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "\n",
        "I want to do more with image detection\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "\n",
        "I would guess that as it grows more accessible, its use will become more widespread\n",
        "- What are the treats posed by AI to our society?\n",
        "\n",
        "One treat is faster tasks done for cheaper. It is a programmer's wet dream. Work really hard to make a thing that does a single task well, and then never have to do that task again\n",
        "- How do you think we can counteract those threats? \n",
        "\n",
        "Improve security. I see articles about companies and governments getting hacked all the time. If a malicious user got access to an AI's code, he or she could subtly influence it to their own gain and it could be hard to notice that somethings wrong.\n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "\n",
        "Yes. I mean, we're biological machines. We exist. We just have to figure out how.\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWwBk6Eo3HqG",
        "colab_type": "code",
        "colab": {},
        "outputId": "5cdd91b4-d606-4198-be6f-f383da54b09b"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}